

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/1.png">
  <link rel="icon" href="/img/1.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#6a598c">
  <meta name="author" content="even zhang">
  <meta name="keywords" content="">
  
    <meta name="description" content="后面有机会会考虑整理一下。 深度学习Q&amp;A以 Q&amp;A 形式收集的一些深度学习的知识。 问答Q: 常规判断A:train loss 不断下降, dev (或 test) loss 不断下降: 说明网络仍在学习; train loss 不断下降，dev (或 test) loss 趋于不变: 说明网络过拟合; train loss 趋于不变，dev (或 test) loss 不断下降">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习Q&amp;A">
<meta property="og:url" content="https://zyweven.github.io/2020/07/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Q&A/index.html">
<meta property="og:site_name" content="Even">
<meta property="og:description" content="后面有机会会考虑整理一下。 深度学习Q&amp;A以 Q&amp;A 形式收集的一些深度学习的知识。 问答Q: 常规判断A:train loss 不断下降, dev (或 test) loss 不断下降: 说明网络仍在学习; train loss 不断下降，dev (或 test) loss 趋于不变: 说明网络过拟合; train loss 趋于不变，dev (或 test) loss 不断下降">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-07-04T02:32:23.000Z">
<meta property="article:modified_time" content="2023-06-08T14:04:10.336Z">
<meta property="article:author" content="even zhang">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary_large_image">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>深度学习Q&amp;A - Even</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"zyweven.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"|","loop":false,"scope":["home"]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null},"gtag":null,"woyaola":null,"cnzz":null},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 50vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Even</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/backgroud3.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">深度学习Q&A</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2020-07-04 10:32" pubdate>
          2020年7月4日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6.5k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          54 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        

      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">深度学习Q&amp;A</h1>
            
            
              <div class="markdown-body">
                
                <p>后面有机会会考虑整理一下。</p>
<h1 id="深度学习Q-A"><a href="#深度学习Q-A" class="headerlink" title="深度学习Q&amp;A"></a>深度学习Q&amp;A</h1><p>以 Q&amp;A 形式收集的一些深度学习的知识。</p>
<h1 id="问答"><a href="#问答" class="headerlink" title="问答"></a>问答</h1><h3 id="Q-常规判断"><a href="#Q-常规判断" class="headerlink" title="Q: 常规判断"></a>Q: 常规判断</h3><p><strong>A:</strong><br>train loss 不断下降, dev (或 test) loss 不断下降: 说明网络仍在学习;</p>
<p>train loss 不断下降，dev (或 test) loss 趋于不变: 说明网络过拟合;</p>
<p>train loss 趋于不变，dev (或 test) loss 不断下降: 说明数据集 100%有问题;</p>
<p>train loss 趋于不变，dev (或 test) loss 趋于不变: 说明学习遇到瓶颈，需要减小学习率或批量数目; 或者是数据集有问题 (数据集标注错误数据比较多)</p>
<p>train loss 不断上升，dev (或 test) loss 不断上升: 说明网络结构设计不当，训练超参数设置不当，数据集未经过清洗等问题。</p>
<h3 id="Q-iteration-和-epoch-有什么区别？"><a href="#Q-iteration-和-epoch-有什么区别？" class="headerlink" title="Q: iteration 和 epoch 有什么区别？"></a>Q: iteration 和 epoch 有什么区别？</h3><p><strong>A:</strong></p>
<p>一次传播 &#x3D; 一次前向传播 + 一次后向传播。（所有的训练样本完成一次 Forword 运算以及一次 BP 运算）</p>
<p>但是考虑到内存不够用的问题，训练样本们往往并不是全都一起拿到内存中去训练，而是一次拿一个 batch 去训练，一个 batch 包含的样本数称为 batch size。</p>
<p>iteration——使用 batch size 个样本传播一次。同样，一次传播 &#x3D; 一次前向传播 + 一次后向传播。</p>
<p>eg. 我们有 1000 个训练样本，batch size 为 100，那么完成一次 epoch 就需要 10 个 iteration。</p>
<h3 id="Q-什么是强化学习？"><a href="#Q-什么是强化学习？" class="headerlink" title="Q: 什么是强化学习？"></a>Q: 什么是强化学习？</h3><p><strong>A:</strong></p>
<h3 id="Q-什么是半监督学习？"><a href="#Q-什么是半监督学习？" class="headerlink" title="Q: 什么是半监督学习？"></a>Q: 什么是半监督学习？</h3><p><strong>A:</strong></p>
<h3 id="Q：什么是偏差，什么是方差？"><a href="#Q：什么是偏差，什么是方差？" class="headerlink" title="Q：什么是偏差，什么是方差？"></a>Q：什么是偏差，什么是方差？</h3><p><strong>A:</strong><br><strong>偏差（bias）</strong>：偏差衡量了模型的预测值与实际值之间的偏离关系。通常在深度学习中，我们每一次训练迭代出来的新模型，都会拿训练数据进行预测，偏差就反应在预测值与实际值匹配度上，比如通常在 keras 运行中看到的准确度为 96%，则说明是低偏差；反之，如果准确度只有 70%，则说明是高偏差。</p>
<p><strong>方差（variance）</strong>：方差描述的是训练数据在不同迭代阶段的训练模型中，预测值的变化波动情况（或称之为离散情况）。从数学角度看，可以理解为每个预测值与预测均值差的平方和的再求平均数。通常在深度学习训练中，初始阶段模型复杂度不高，为低方差；随着训练量加大，模型逐步拟合训练数据，复杂度开始变高，此时方差会逐渐变高。<br>![[image-20230215210503598.png]]<br><strong>低偏差，低方差</strong>：这是训练的理想模型，此时蓝色点集基本落在靶心范围内，且数据离散程度小，基本在靶心范围内；</p>
<p><strong>低偏差，高方差</strong>：这是深度学习面临的最大问题，过拟合了。也就是模型太贴合训练数据了，导致其泛化（或通用）能力差，若遇到测试集，则准确度下降的厉害；</p>
<p><strong>高偏差，低方差</strong>：这往往是训练的初始阶段；</p>
<p><strong>高偏差，高方差</strong>：这是训练最糟糕的情况，准确度差，数据的离散程度也差。<br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/hutao722/p/9921788.html">https://www.cnblogs.com/hutao722/p/9921788.html</a></p>
<h3 id="Q：什么是卷积？什么是池化？"><a href="#Q：什么是卷积？什么是池化？" class="headerlink" title="Q：什么是卷积？什么是池化？"></a>Q：什么是卷积？什么是池化？</h3><p><strong>A:</strong></p>
<h3 id="Q：什么是多标签分类？"><a href="#Q：什么是多标签分类？" class="headerlink" title="Q：什么是多标签分类？"></a>Q：什么是多标签分类？</h3><p><strong>A:</strong> 在一些复杂场景下，一个 object 可能属于多个类，比如你的类别中有 woman 和 person 这两个类，那么如果一张图像中有一个 woman，那么你检测的结果中类别标签就要同时有 woman 和 person 两个类，这就是多标签分类</p>
<h3 id="Q：什么是回归模型，什么是分类模型？"><a href="#Q：什么是回归模型，什么是分类模型？" class="headerlink" title="Q：什么是回归模型，什么是分类模型？"></a>Q：什么是回归模型，什么是分类模型？</h3><p><strong>A:</strong><br><strong>分类</strong><br>分类是指有有限个可能的问题，预测的是一个离散的、明确的变量。比如给出一张图片，去判断是 T 恤是裤子或者其他的种类；这个类别是有限的。目标检测算法中，RCNN 系列就是用了分类问题的思想，先是找出一定量的 region proposal（候选区域），然后再对这些个候选区域进行分类任务。</p>
<p><strong>回归</strong><br>相反，回归是指有无限个可能的问题，预测的是一个连续的、逼近的变量。比如房价的预测、明日气温的预测。同样，目标检测算法中，yolo 系列则是用来回归的思想，没有提取候选区域这一步，直接划分为一些 cell，然后产出 bbox，回归出这些 bbox 的位置和置信度。</p>
<h3 id="Q：什么是先验，后验，似然？"><a href="#Q：什么是先验，后验，似然？" class="headerlink" title="Q：什么是先验，后验，似然？"></a>Q：什么是先验，后验，似然？</h3><p><strong>A:</strong><br>先验分布：根据一般的经验认为随机变量应该满足的分布<br>后验分布：通过当前训练数据修正的随机变量的分布，比先验分布更符合当前数据<br>似然估计：已知训练数据，给定了模型，通过让似然性极大化估计模型参数的一种方法<br>后验分布往往是基于先验分布和极大似然估计计算出来的。</p>
<p>隔壁老王要去 10 公里外的一个地方办事，他可以选择走路，骑自行车或者开车，并花费了一定时间到达目的地。在这个事件中，可以把交通方式（走路、骑车或开车）认为是原因，花费的时间认为是结果。若老王花了一个小时的时间完成了 10 公里的距离，那么很大可能是骑车过去的，当然也有较小可能老王是个健身达人跑步过去的，或者开车过去但是堵车很严重。若老王一共用了两个小时的时间完成了 10 公里的距离，那么很有可能他是走路过去的。若老王只用了二十分钟，那么很有可能是开车。这种先知道结果，然后由结果估计原因的概率分布，p (交通方式|时间)，就是后验概率。</p>
<p>老王早上起床的时候觉得精神不错，想锻炼下身体，决定跑步过去；也可能老王想做个文艺青年试试最近流行的共享单车，决定骑车过去；也可能老王想炫个富，决定开车过去。老王的选择与到达目的地的时间无关。先于结果，确定原因的概率分布，p (交通方式)，就是先验概率。</p>
<p>老王决定步行过去，那么很大可能 10 公里的距离大约需要两个小时；较小可能是老王平时坚持锻炼，跑步过去用了一个小时；更小可能是老王是个猛人，40 分钟就到了。老王决定骑车过去，很可能一个小时就能到；较小可能是老王那天精神不错加上单双号限行交通很通畅，40 分钟就到了；还有一种较小可能是老王运气很差，连着坏了好几辆共享单车，花了一个半小时才到。老王决定开车过去，很大可能是 20 分钟就到了，较小可能是那天堵车很严重，磨磨唧唧花了一个小时才到。这种先确定原因，根据原因来估计结果的概率分布，p (时间|交通方式)，就是似然估计。</p>
<p>老王去那个地方好几趟，不管是什么交通方式，得到了一组关于时间的概率分布。这种不考虑原因，只看结果的概率分布，p (时间)，也有一个名词：evidence（不清楚合适的中文名是什么）</p>
<h3 id="Q：-论文中常见的-Top-1-准确率和-Top-5-准确率（Top-1-Error-Top-5-Error）是什么意思？"><a href="#Q：-论文中常见的-Top-1-准确率和-Top-5-准确率（Top-1-Error-Top-5-Error）是什么意思？" class="headerlink" title="Q： 论文中常见的 Top-1 准确率和 Top-5 准确率（Top-1 Error&amp;Top-5 Error）是什么意思？"></a>Q： 论文中常见的 Top-1 准确率和 Top-5 准确率（Top-1 Error&amp;Top-5 Error）是什么意思？</h3><p><strong>A:</strong><br>ImageNet 有大概 1000 个分类，而模型预测某张图片时，会给出 1000 个按概率从高到低的类别排名。</p>
<p>所谓的 Top-1 Accuracy 是指排名第一的类别与实际结果相符的准确率<br>而 Top-5 Accuracy 是指排名前五的类别包含实际结果的准确率。</p>
<p>Top-1 Error：假设模型预测某个对象的类别，模型输出 1 个预测结果，那么这一个结果能判断正确的概率就是 Top-1 正确率。判断错误的概率就是 Top-1 错误率。简言之就是模型判错的概率。<br>Top-5 Error ：假设模型预测某个对象的类别，模型输出 5 个预测结果，只要其中一个能判断正确类别，这个概率就是 Top-5 正确率，反之，预测输出的五个结果都错误的概率就是 Top-5 错误率。<br>一般来说，Top-1 Error 和 Top-5 Error 越低，模型的性能也就越好。且 Top-5 Error 往往小于 Top-1 Error。</p>
<h3 id="Q：怎么设置学习速率的优化策略？学习速率的优化策略有哪些？"><a href="#Q：怎么设置学习速率的优化策略？学习速率的优化策略有哪些？" class="headerlink" title="Q：怎么设置学习速率的优化策略？学习速率的优化策略有哪些？"></a>Q：怎么设置学习速率的优化策略？学习速率的优化策略有哪些？</h3><p><strong>A:</strong><br><a target="_blank" rel="noopener" href="https://lumingdong.cn/setting-strategy-of-gradient-descent-learning-rate.html">https://lumingdong.cn/setting-strategy-of-gradient-descent-learning-rate.html</a></p>
<h3 id="Q：-什么是-one-stage-什么的是-two-stage-两者的区别是什么？"><a href="#Q：-什么是-one-stage-什么的是-two-stage-两者的区别是什么？" class="headerlink" title="Q： 什么是 one-stage 什么的是 two-stage 两者的区别是什么？"></a>Q： 什么是 one-stage 什么的是 two-stage 两者的区别是什么？</h3><p><strong>A:</strong><br>one-stage 一次性进行定位+类型预测<br>two-stage 先定位再预测？</p>
<h3 id="Q-什么是-LSTM-Net"><a href="#Q-什么是-LSTM-Net" class="headerlink" title="Q: 什么是 LSTM Net?"></a>Q: 什么是 LSTM Net?</h3><p><strong>A:</strong>:</p>
<p>参考：<br><a target="_blank" rel="noopener" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p>
<h3 id="Q-什么是-Contrastive-Learning-对比学习"><a href="#Q-什么是-Contrastive-Learning-对比学习" class="headerlink" title="Q: 什么是 Contrastive Learning (对比学习)?"></a>Q: 什么是 Contrastive Learning (对比学习)?</h3><p><strong>A:</strong>:</p>
<p>参考：</p>
<h3 id="Q-什么是-Optimization-in-Multi-task-learning-多任务学习优化"><a href="#Q-什么是-Optimization-in-Multi-task-learning-多任务学习优化" class="headerlink" title="Q: 什么是 Optimization in Multi-task learning (多任务学习优化)?"></a>Q: 什么是 Optimization in Multi-task learning (多任务学习优化)?</h3><p><strong>A:</strong>:</p>
<p>参考：</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/269492239">https://zhuanlan.zhihu.com/p/269492239</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/EDDSWyo8goRKG_bXohKUcA">https://mp.weixin.qq.com/s/EDDSWyo8goRKG_bXohKUcA</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/JaMSZfJZ6zPEOueuVg6XHw">https://mp.weixin.qq.com/s/JaMSZfJZ6zPEOueuVg6XHw</a> loss 设计</p>
<h3 id="Q-什么是-pretext-task-前置任务"><a href="#Q-什么是-pretext-task-前置任务" class="headerlink" title="Q: 什么是 pretext task (前置任务)?"></a>Q: 什么是 pretext task (前置任务)?</h3><p><strong>A:</strong>:<br>Pretext task 也叫 surrogate task，我更倾向于把它翻译为：代理任务。</p>
<p>参考：<br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/358468168">https://www.zhihu.com/question/358468168</a><br><a target="_blank" rel="noopener" href="https://atcold.github.io/pytorch-Deep-Learning/zh/week01/01-1/">https://atcold.github.io/pytorch-Deep-Learning/zh/week01/01-1/</a>  (非常好的一个课程)<br><a target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/404602/pretext-task-in-computer-vision">https://stats.stackexchange.com/questions/404602/pretext-task-in-computer-vision</a></p>
<h3 id="Q-什么是-Downstream-Task-下游任务"><a href="#Q-什么是-Downstream-Task-下游任务" class="headerlink" title="Q: 什么是 Downstream Task (下游任务)?"></a>Q: 什么是 Downstream Task (下游任务)?</h3><p><strong>A:</strong>：</p>
<p>参考：</p>
<h3 id="Q-什么是-Few-Shot-Learning-小样本学习"><a href="#Q-什么是-Few-Shot-Learning-小样本学习" class="headerlink" title="Q: 什么是 Few-Shot Learning (小样本学习)?"></a>Q: 什么是 Few-Shot Learning (小样本学习)?</h3><p><strong>A:</strong>:</p>
<p>参考：</p>
<h3 id="Q-什么是-Meta-learning-元学习"><a href="#Q-什么是-Meta-learning-元学习" class="headerlink" title="Q: 什么是 Meta learning (元学习)?"></a>Q: 什么是 Meta learning (元学习)?</h3><p><strong>A:</strong>:</p>
<p>参考：</p>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=EkAqYbpCYAc">https://www.youtube.com/watch?v=EkAqYbpCYAc</a></p>
<h3 id="Q-什么是-life-long-Learning-终生学习"><a href="#Q-什么是-life-long-Learning-终生学习" class="headerlink" title="Q: 什么是 life long Learning (终生学习)"></a>Q: 什么是 life long Learning (终生学习)</h3><p><strong>A:</strong>:</p>
<p>参考： <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/119324185">https://zhuanlan.zhihu.com/p/119324185</a></p>
<h3 id="Q-什么是-Curriculum-Learning-课程学习"><a href="#Q-什么是-Curriculum-Learning-课程学习" class="headerlink" title="Q: 什么是 Curriculum Learning (课程学习)?"></a>Q: 什么是 Curriculum Learning (课程学习)?</h3><p><strong>A:</strong>:</p>
<p>参考： <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/362351969">https://zhuanlan.zhihu.com/p/362351969</a></p>
<h3 id="Q-什么是-Zero-Shot-Learning-零样本学习"><a href="#Q-什么是-Zero-Shot-Learning-零样本学习" class="headerlink" title="Q: 什么是 Zero-Shot Learning (零样本学习)?"></a>Q: 什么是 Zero-Shot Learning (零样本学习)?</h3><p><strong>A:</strong>:</p>
<p>参考：</p>
<h3 id="Q-什么是-蒸馏学习"><a href="#Q-什么是-蒸馏学习" class="headerlink" title="Q: 什么是 蒸馏学习?"></a>Q: 什么是 蒸馏学习?</h3><p><strong>A:</strong></p>
<p>参考：</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/102038521">https://zhuanlan.zhihu.com/p/102038521</a></p>
<h2 id="Q：什么是异常检测（Anomaly-Detection）"><a href="#Q：什么是异常检测（Anomaly-Detection）" class="headerlink" title="Q：什么是异常检测（Anomaly Detection）"></a>Q：什么是异常检测（Anomaly Detection）</h2><p><strong>A:</strong></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/bLcb9QvdY4pOu6CEME0aeQ">https://mp.weixin.qq.com/s/bLcb9QvdY4pOu6CEME0aeQ</a></p>
<h2 id="Q：什么是目标跟踪？"><a href="#Q：什么是目标跟踪？" class="headerlink" title="Q：什么是目标跟踪？"></a>Q：什么是目标跟踪？</h2><p><strong>A:</strong></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/GdEmAZokncFDrcIsj9luug">https://mp.weixin.qq.com/s/GdEmAZokncFDrcIsj9luug</a></p>
<h2 id="Q：什么是图像匹配？"><a href="#Q：什么是图像匹配？" class="headerlink" title="Q：什么是图像匹配？"></a>Q：什么是图像匹配？</h2><p><strong>A:</strong></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/Q6bdbRBHnIPh_zdL5nkOyw">https://mp.weixin.qq.com/s/Q6bdbRBHnIPh_zdL5nkOyw</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/3fJ8Z0WIGOoUymEsTw30LQ">https://mp.weixin.qq.com/s/3fJ8Z0WIGOoUymEsTw30LQ</a></p>
<h2 id="Q：什么是多模态深度学习？"><a href="#Q：什么是多模态深度学习？" class="headerlink" title="Q：什么是多模态深度学习？"></a>Q：什么是多模态深度学习？</h2><p><strong>A:</strong></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/0CUGispeZS04D6NhGkrucw">https://mp.weixin.qq.com/s/0CUGispeZS04D6NhGkrucw</a></p>
<h2 id="Q：什么是-SPPnet？他能解决什么问题？"><a href="#Q：什么是-SPPnet？他能解决什么问题？" class="headerlink" title="Q：什么是 SPPnet？他能解决什么问题？"></a>Q：什么是 SPPnet？他能解决什么问题？</h2><p><strong>A:</strong><br>参考： <a target="_blank" rel="noopener" href="https://blog.csdn.net/yzf0011/article/details/75212513">https://blog.csdn.net/yzf0011/article/details/75212513</a>  spp 深度解析<br>优点：</p>
<ul>
<li>可以提取不同尺寸的空间特征信息，可以提升模型对于空间布局和物体变性的鲁棒性。</li>
<li>可以避免将图片 resize、crop 成固定大小输入模型的弊端。<br>SPP 和 Fast R-CNN 的 ROI Pooling 是一脉相承的。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-comment"># https://github.com/yueruchen/sppnet-pytorch/blob/master/spp_layer.py</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">spatial_pyramid_pool</span>(<span class="hljs-params">self, previous_conv, num_sample, previous_conv_size, out_pool_size</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    previous_conv: a tensor vector of previous convolution layer</span><br><span class="hljs-string">    num_sample: an int number of image in the batch</span><br><span class="hljs-string">    previous_conv_size: an int vector [height, width] of the matrix features size of previous convolution layer</span><br><span class="hljs-string">    out_pool_size: a int vector of expected output size of max pooling layer</span><br><span class="hljs-string">    returns: a tensor vector with shape [1 x n] is the concentration of multi-level pooling</span><br><span class="hljs-string">    previous_conv:前卷积层的张量向量</span><br><span class="hljs-string">    num_sample：批处理中图像的整数</span><br><span class="hljs-string">    previous_conv_size：矩阵的int向量[高度，宽度]表示上一个卷积层的大小</span><br><span class="hljs-string">    out_pool_size</span><br><span class="hljs-string">    returns：形状为[1 x n]的张量向量是多级池的集中</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># print(previous_conv.size())</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(out_pool_size)):<br>        <span class="hljs-comment"># print(previous_conv_size)</span><br>        h_wid = <span class="hljs-built_in">int</span>(math.ceil(previous_conv_size[<span class="hljs-number">0</span>] / out_pool_size[i]))<br>        w_wid = <span class="hljs-built_in">int</span>(math.ceil(previous_conv_size[<span class="hljs-number">1</span>] / out_pool_size[i]))<br>        h_pad = (h_wid * out_pool_size[i] - previous_conv_size[<span class="hljs-number">0</span>] + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span><br>        w_pad = (w_wid * out_pool_size[i] - previous_conv_size[<span class="hljs-number">1</span>] + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span><br>        maxpool = nn.MaxPool2d((h_wid, w_wid), stride=(h_wid, w_wid), padding=(h_pad, w_pad))<br>        x = maxpool(previous_conv)<br>        <span class="hljs-keyword">if</span> (i == <span class="hljs-number">0</span>):<br>            spp = x.view(num_sample, -<span class="hljs-number">1</span>)<br>            <span class="hljs-comment"># print(&quot;spp size:&quot;,spp.size())</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># print(&quot;size:&quot;,spp.size())</span><br>            spp = torch.cat((spp, x.view(num_sample, -<span class="hljs-number">1</span>)), <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> spp<br></code></pre></td></tr></table></figure>

<h3 id="Q：什么是消融实验（Ablation-experiment）？"><a href="#Q：什么是消融实验（Ablation-experiment）？" class="headerlink" title="Q：什么是消融实验（Ablation experiment）？"></a>Q：什么是消融实验（Ablation experiment）？</h3><p><strong>A:</strong><br>采用“消融研究”来描述去除网络的某些部分的过程，以便更好地理解网络的行为。</p>
<p>作者提出了一种方案，同时改变了多个条件&#x2F;参数，他在接下去的消融实验中，会一一控制一个条件&#x2F;参数不变，来看看结果，到底是哪个条件&#x2F;参数对结果的影响更大。</p>
<p>对于一个问题 Q，原先有个方法 A。然后你提出一个创新点，得到 A+的方法 B。为了比较创新点的作用，你要控制 B 中关于 A 的实验的参数，并改变创新点。进行 A 和 B 对比实验。看创新点是否有效。</p>
<p>有点控制变量的意思。</p>
<h2 id="Q：什么是-end-to-end"><a href="#Q：什么是-end-to-end" class="headerlink" title="Q：什么是 end to end?"></a>Q：什么是 end to end?</h2><p><strong>A:</strong><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/51435499">https://www.zhihu.com/question/51435499</a><br>大概意思就是：<br>输入原始数据，直接得到最后的结果，且网络从头到尾是可导的。中间无需人工干预。</p>
<p>end-to-end 训练只用一个阶段，如：Fast R-CNN，Faster R-CNN<br>而 R-CNN、SPP 训练需要分为多个阶段：微调网络+训练 SVM+训练边框回归器</p>
<p>以下是知乎的一个解释，答主要就语音识别领域来讲的，图像领域有所不同，“图像识别和语音识别任务不一样”<br><strong>端到端训练</strong>（end-to-end training）：一般指的是在训练好语言模型后，将声学模型和语言模型接在一起，以 WER 或它的一种近似为目标函数去训练声学模型。由于训练声学模型时要计算系统整体的输出，所以称为「端到端」训练。可以看出这种方法并没有彻底解决问题，因为语言模型还是独立训练的。</p>
<p><strong>端到端模型</strong>（end-to-end models）：系统中不再有独立的声学模型、发音词典、语言模型等模块，而是从输入端（语音波形或特征序列）到输出端（单词或字符序列）直接用一个神经网络相连，让这个神经网络来承担原先所有模块的功能。典型的代表如使用 CTC 的 EESEN [1]、使用注意力机制的 Listen, Attend and Spell [2]。这种模型非常简洁，但灵活性就差一些：一般来说用于训练语言模型的文本数据比较容易大量获取，但不与语音配对的文本数据无法用于训练端到端的模型。因此，端到端模型也常常再外接一个语言模型，用于在解码时调整候选输出的排名（rescoring），如 [1]</p>
<p>链接： <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/51435499/answer/129429628">https://www.zhihu.com/question/51435499/answer/129429628</a></p>
<h2 id="Q：-什么是多尺度训练，什么是-FPN？两者是什么关系？什么的-FRN？"><a href="#Q：-什么是多尺度训练，什么是-FPN？两者是什么关系？什么的-FRN？" class="headerlink" title="Q： 什么是多尺度训练，什么是 FPN？两者是什么关系？什么的 FRN？"></a>Q： 什么是多尺度训练，什么是 FPN？两者是什么关系？什么的 FRN？</h2><p><strong>A:</strong><br>参考： <a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1546594">https://cloud.tencent.com/developer/article/1546594</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/57cfa4fdd423">https://www.jianshu.com/p/57cfa4fdd423</a><br>多尺度训练是一种数据处理方式（？）同一张图片以不同的尺寸输入模型进行训练（或者不同的图片以不同的尺寸输入模型？）<br>FPN（特征金字塔）是一种网络结构。对于小目标来说，当进行卷积池化到最后一层，实际上语义信息已经没有了，所以为了解决多尺度检测的问题，引入了特征金字塔网络。</p>
<h2 id="Q-什么是-VAE-Variational-Auto-Encoder"><a href="#Q-什么是-VAE-Variational-Auto-Encoder" class="headerlink" title="Q: 什么是 VAE (Variational Auto Encoder)?"></a>Q: 什么是 VAE (Variational Auto Encoder)?</h2><p><strong>A:</strong></p>
<h2 id="Q-什么是能量图"><a href="#Q-什么是能量图" class="headerlink" title="Q: 什么是能量图?"></a>Q: 什么是能量图?</h2><p><strong>A:</strong></p>
<h2 id="什么是-Seam-Carving-算法，如何实现？"><a href="#什么是-Seam-Carving-算法，如何实现？" class="headerlink" title="什么是 Seam Carving 算法，如何实现？"></a>什么是 Seam Carving 算法，如何实现？</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/38974520">https://zhuanlan.zhihu.com/p/38974520</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/65339171">https://zhuanlan.zhihu.com/p/65339171</a><br><a target="_blank" rel="noopener" href="https://github.com/avidLearnerInProgress/pyCAIR">https://github.com/avidLearnerInProgress/pyCAIR</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/85136353">https://zhuanlan.zhihu.com/p/85136353</a><br><a target="_blank" rel="noopener" href="http://cs.brown.edu/courses/cs129/results/proj3/taox/">http://cs.brown.edu/courses/cs129/results/proj3/taox/</a></p>
<h2 id="Q：-1×1-卷积核的作用"><a href="#Q：-1×1-卷积核的作用" class="headerlink" title="Q： 1×1 卷积核的作用"></a>Q： 1×1 卷积核的作用</h2><p><strong>A:</strong><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/40050371">https://zhuanlan.zhihu.com/p/40050371</a></p>
<p>卷积核的作用在于特征的抽取，越是大的卷积核尺寸就意味着更大的感受野</p>
<p><strong>降维（减少参数）&#x2F;升维</strong></p>
<p>当 1*1 卷积出现时，在大多数情况下它作用是升&#x2F;降特征的维度，这里的维<br>度指的是通道数（厚度），而不改变图片的宽和高。</p>
<p>1×1 卷积核可以起到一个跨通道聚合的作用，所以进一步可以起到降维（或者升维）的作用，起到减少参数的目的。<br>比如当前层为 x×x×m 即图像大小为 x×x，特征层数为 m，然后如果将其通过 1×1 的卷积核，特征层数为 n，那么只要 n&lt;m 这样就能起到降维的目的，减少之后步骤的运算量（当然这里不太严谨，需要考虑 1×1 卷积核本身的参数个数为 m×nm×n 个）。</p>
<p>如果卷积的输出输入都只是一 个平面，那么 1x1 卷积核并没有什么意义，它是完全不考虑像素与周边其他像素关系。 但卷积的输出输入是长方体，所以 1x1 卷积实际上是对每个像素点，在不同的 channels_上进行线性组合 (信息整合) ，且保留了图片的原有平面结构, 调控 depth, 从而完成升维或降维的功能。</p>
<p><strong>加入非线性</strong></p>
<p>卷积层之后经过激励层，1*1 的卷积在前一层的学习表示上添加了非线性激励（ non-linear activation ），提升网络的表达能力；</p>
<p><strong>跨通道信息交互（channal 的变换）</strong></p>
<p>例子：使用 1×1 卷积核，实现降维和升维的操作其实就是 channel 间信息的线性组合变化，3×3，64channels 的卷积核后面添加一个 1×1，28channels 的卷积核，就变成了 3×3，28channels 的卷积核，原来的 64 个 channels 就可以理解为跨通道线性组合变成了 28channels，这就是通道间的信息交互。</p>
<p>注意：只是在 channel 维度上做线性组合，W 和 H 上是共享权值的 sliding window</p>
<h2 id="Q：-常用-Normalization-的区别：BN-LN-IN-GN"><a href="#Q：-常用-Normalization-的区别：BN-LN-IN-GN" class="headerlink" title="Q： 常用 Normalization 的区别：BN, LN, IN, GN"></a>Q： 常用 Normalization 的区别：BN, LN, IN, GN</h2><p><strong>A:</strong><br>![[image-20230215210441926.png]]<br>Batch Normalization (BN)、Layer Normalization (LN)、Instance Normalization (IN)、Group Normalization (GN)<br>这几个方法主要的区别就是在：</p>
<ol>
<li><p>BN 是在 batch 上，对 N、H、W 做归一化，而保留通道 C 的维度。BN 对较小的 batch size 效果不好。BN 适用于固定深度的前向神经网络，如 CNN，不适用于 RNN；</p>
</li>
<li><p>LN 在通道方向上，对 C、H、W 归一化，主要对 RNN 效果明显；</p>
</li>
<li><p>IN 在图像像素上，对 H、W 做归一化，用在风格化迁移</p>
</li>
<li><p>GN 将 channel 分组，然后再做归一化。</p>
</li>
</ol>
<p>将 feature map shape 记为[N, C, H, W]。如果把特征图比喻成一摞书，这摞书总共有 N 本，每本有 C 页，每页有 H 行，每行有 W 个字符。</p>
<ol>
<li>BN 是在 batch 上，对 N、H、W 做归一化，而保留通道 C 的维度。BN 相当于把这些书按页码一一对应地加起来，再除以每个页码下的字符总数：N×H×W。</li>
<li>LN 在通道方向上，对 C、H、W 归一化。LN 相当于把每一本书的所有字加起来，再除以这本书的字符总数：C×H×W。</li>
<li>IN 在图像像素上，对 H、W 做归一化。IN 相当于把一页书中所有字加起来，再除以该页的总字数：H×W。</li>
<li>GN 将 channel 分组，然后再做归一化。GN 相当于把一本 C 页的书平均分成 G 份，每份成为有 C&#x2F;G 页的小册子，对每个小册子做 Norm。</li>
</ol>
<p>其中 GN，pytorch 已经有实现<br><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/nn.html#torch.nn.GroupNorm">https://pytorch.org/docs/stable/nn.html#torch.nn.GroupNorm</a></p>
<pre><code class="hljs">参考：
  1、 https://blog.csdn.net/ft_sunshine/article/details/99203548?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task
  2、https://mp.weixin.qq.com/s/HK4Ajk363GOoO1P5Js8Deg
</code></pre>
<h2 id="Q-什么是-surrogate-losses-代理函数-？"><a href="#Q-什么是-surrogate-losses-代理函数-？" class="headerlink" title="Q: 什么是 surrogate losses (代理函数)？"></a>Q: 什么是 surrogate losses (代理函数)？</h2><p><strong>A:</strong> 中文可以译为代理损失函数。当原本的 loss function 不便计算的时候，我们就会考虑使用 surrogate loss function。</p>
<p><strong>参考</strong>：<br><a target="_blank" rel="noopener" href="http://sofasofa.io/forum_main_post.php?postid=1000605">http://sofasofa.io/forum_main_post.php?postid=1000605</a></p>
<h2 id="Q：-探究各种新出的优化器的优缺点"><a href="#Q：-探究各种新出的优化器的优缺点" class="headerlink" title="Q： 探究各种新出的优化器的优缺点"></a>Q： 探究各种新出的优化器的优缺点</h2><p><strong>A:</strong><br><a target="_blank" rel="noopener" href="https://github.com/jettify/pytorch-optimizer">https://github.com/jettify/pytorch-optimizer</a></p>
<h2 id="Q：我们需要模型压缩吗？"><a href="#Q：我们需要模型压缩吗？" class="headerlink" title="Q：我们需要模型压缩吗？"></a>Q：我们需要模型压缩吗？</h2><p><strong>A:</strong></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/HqiTdsZv_9aERq0tjBuO1A">https://mp.weixin.qq.com/s/HqiTdsZv_9aERq0tjBuO1A</a></p>
<h2 id="Q：什么是-mae-什么是-mRMSE，什么是-MSE"><a href="#Q：什么是-mae-什么是-mRMSE，什么是-MSE" class="headerlink" title="Q：什么是 mae, 什么是 mRMSE，什么是 MSE"></a>Q：什么是 mae, 什么是 mRMSE，什么是 MSE</h2><p><strong>A:</strong><br><strong>平均绝对误差 (MAE)</strong> 和 <strong>均方差误差 (RMSE)</strong> 是用来衡量连续变量精度的两个最常用的指标。</p>
<ul>
<li>平均绝对误差 (MAE)<br><a target="_blank" rel="noopener" href="https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d">https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d</a><br>平均绝对误差 (MAE) : MAE 测量在一组预测中的平均误差大小，没有考虑它们的方向。 它是预测与实际观测之间的绝对差异在测试样本上的平均值，其中所有的个体差异具有相同的权重。</li>
</ul>
<p>根均方差 (RMSE) : 也可以度量误差的平均值。 它是预测值与实际观测值平方差的平方根。</p>
<h2 id="Q：什么是标签平滑，什么时候使用标签平滑？"><a href="#Q：什么是标签平滑，什么时候使用标签平滑？" class="headerlink" title="Q：什么是标签平滑，什么时候使用标签平滑？"></a>Q：什么是标签平滑，什么时候使用标签平滑？</h2><p><strong>A:</strong><br><a target="_blank" rel="noopener" href="https://www.jiqizhixin.com/articles/2019-07-09-7">https://www.jiqizhixin.com/articles/2019-07-09-7</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_37947156/article/details/95936642?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase">https://blog.csdn.net/weixin_37947156/article/details/95936642?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase</a></p>
<h2 id="Q：-什么是-P-R-mAP-F1"><a href="#Q：-什么是-P-R-mAP-F1" class="headerlink" title="Q： 什么是 P, R, mAP, F1?"></a>Q： 什么是 P, R, mAP, F1?</h2><p><strong>A:</strong><br>Precision – 查准率、精确率</p>
<p>Recall – 查全率、召回率</p>
<p>![[image-20230215210422593.png]]</p>
<p>注意：准确率和召回率是互相影响的，理想情况下肯定是做到两者都高，但是一般情况下准确率高、召回率就低，召回率低、准确率高，当然如果两者都低，那是什么地方出问题了 。</p>
<p>如果是做搜索，那就是保证召回的情况下提升准确率；如果做疾病监测、反垃圾，则是保准确率的条件下，提升召回</p>
<p>所以，在两者都要求高的情况下，可以用 F1 来衡量。</p>
<p>$$F1&#x3D;2 \times P\times R&#x2F;(P+R)$$<br>PR 曲线下的面积, 叫做 AP (average precision), N 个分类类别得到 N 条 PR 曲线得到 N 个 AP, 求平均得到 mAP (mean average precision).</p>
<p>具体计算过程: (目标检测为例)</p>
<p>先把所有 bbox 找出来 并加上 confidence<br>然后每一类根据 confidence 从大到小排列<br>每一类中每个 confidence 计算与 label 对应的 IOU, 根据设定的 IOU 阈值判断是否预测正确<br>每一类中每个 confidence 根据预测正误算出其 recall 和 precision 得到每一类的 PR 曲线, 曲线下的面积为对应该类的 average precision<br>所有类取 mean, 得到对应 IOU 阈值下的 mean average precision, 如 mAP50, mAP75 等等 (YOLO 论文中叫 AP50, AP75).</p>
<p>$$mAP&#x3D;\int_{0}^{1}P(R)dR$$</p>
<p>参考： <a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42561002/article/details/90409951">https://blog.csdn.net/weixin_42561002/article/details/90409951</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_34690929/article/details/79970565">https://blog.csdn.net/qq_34690929/article/details/79970565</a></p>
<h2 id="Q：什么是棋盘效应（Checkerboard-Artifacts）？"><a href="#Q：什么是棋盘效应（Checkerboard-Artifacts）？" class="headerlink" title="Q：什么是棋盘效应（Checkerboard Artifacts）？"></a>Q：什么是棋盘效应（Checkerboard Artifacts）？</h2><p><strong>A:</strong></p>
<p>棋盘效应：主要体现在 GAN 中，指网络生成的图像放大后呈现深浅不一的样子和棋盘有点像。所以叫做棋盘效应。(相邻像素之间颜色相似但不相同（？）)<br>产生原因：使用反卷积 (deconvolution&#x2F;转置卷积)，deconvolution layer 可以允许模型通过每一个点进行绘制高分辨率图像上的一个方块，这种情况的产生与 deconvolution 的 stride、kernel size 有关。<br><strong>如何避免棋盘效应？</strong><br>第一种方法是用到的反卷积核的大小可被步长整除，从而避免重叠效应。与最近成功用于图像超分辨率的技术“子像素卷积”（sub-pixel convolution）等价。</p>
<p>另一种方法是从卷积操作中分离出对卷积后更高分辨率的特征图上采样来计算特征。例如，可以先缩放图像（最近邻插值或双线性插值），再卷积。貌似是个自然的方法。<br>（原文中说最近邻插值比双线性插值好）<br><strong>Code</strong><br>    Resize-convolution layers can be easily implemented in TensorFlow using <strong>tf. image. resize_images ()</strong>. For best results, use <strong>tf. pad ()</strong> before doing convolution with <strong>tf. nn. conv2d ()</strong> to avoid boundary artifacts.</p>
<p><a target="_blank" rel="noopener" href="https://distill.pub/2016/deconv-checkerboard/">https://distill.pub/2016/deconv-checkerboard/</a>   <strong>best</strong></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/hellcat/p/9707204.html">https://www.cnblogs.com/hellcat/p/9707204.html</a></p>
<h2 id="Q：Sub-pixel-Convolution-子像素卷积-？"><a href="#Q：Sub-pixel-Convolution-子像素卷积-？" class="headerlink" title="Q：Sub-pixel Convolution (子像素卷积)？"></a>Q：Sub-pixel Convolution (子像素卷积)？</h2><p><strong>A:</strong><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/leviopku/article/details/84975282">https://blog.csdn.net/leviopku/article/details/84975282</a></p>
<h2 id="Q-什么是-LR-HR-SR-图像超分辨率"><a href="#Q-什么是-LR-HR-SR-图像超分辨率" class="headerlink" title="Q: 什么是 LR, HR, SR (图像超分辨率)?"></a>Q: 什么是 LR, HR, SR (图像超分辨率)?</h2><p><strong>A:</strong><br>LR: 低分辨率（简称 LR）图像<br>HR: 高分辨率（简称 HR）图像</p>
<ul>
<li>高分辨率意味着图像中的像素密度高，能够提供更多的细节，而这些细节在许多实际应用中不可或缺。</li>
</ul>
<p>SR: 从多个可观察到的低分辨率（简称 LR）图像得到高分辨率图像，文献中将其称为：超分辨率（简称 SR 或者 HR）图像复原或者简单地叫做分辨率增强。</p>
<p>图像超分辨率的英文名称是 (Image Super Resolution)。图像超分辨率是指由一幅低分辨率图像或图像序列恢复出高分辨率图像。图像超分辨率技术分为超分辨率复原和超分辨率重建。目前， 图像超分辨率研究可分为 3 个主要范畴： 基于插值、 基于重建和基于学习的方法．<br>超分辨率 (Super-Resolution) 即通过硬件或软件的方法提高原有图像的分辨率，通过一系列低分辨率的图像来得到一幅高分辨率的图像过程就是超分辨率重建。超分辨率重建的核心思想就是用时间带宽 (获取同一场景的多帧图像序列) 换取空间分辨率, 实现时间分辨率向空间分辨率的转换。</p>
<p>参考：<br><a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%9B%BE%E5%83%8F%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/1608635?fr=aladdin">https://baike.baidu.com/item/%E5%9B%BE%E5%83%8F%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/1608635?fr=aladdin</a>  （值得一看）</p>
<h2 id="Q-什么是-Embedding？"><a href="#Q-什么是-Embedding？" class="headerlink" title="Q: 什么是 Embedding？"></a>Q: 什么是 Embedding？</h2><p><strong>A：</strong><br>Embedding 是一个将离散变量转为连续向量表示的一个方式<br>embedding 就是用一个低维的向量表示一个物体，可以是一个词，或是一个商品，或是一个电影等等。这个 embedding 向量的性质是能使距离相近的向量对应的物体有相近的含义，比如 Embedding (复仇者联盟) 和 Embedding (钢铁侠) 之间的距离就会很接近，但 Embedding (复仇者联盟) 和 Embedding (乱世佳人) 的距离就会远一些。</p>
<p>除此之外 Embedding 甚至还具有数学运算的关系，比如 Embedding（马德里）-Embedding（西班牙）+Embedding (法国)≈Embedding (巴黎)<br>参考：<br><a target="_blank" rel="noopener" href="https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526">https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526</a><br><a target="_blank" rel="noopener" href="https://www.jiqizhixin.com/articles/2019-03-27-7">https://www.jiqizhixin.com/articles/2019-03-27-7</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/38002635">https://www.zhihu.com/question/38002635</a></p>
<h2 id="Q：什么是-Ensemble-Method（集成学习）"><a href="#Q：什么是-Ensemble-Method（集成学习）" class="headerlink" title="Q：什么是 Ensemble Method（集成学习）?"></a>Q：什么是 Ensemble Method（集成学习）?</h2><p><strong>A：</strong> 注意，ensemble 和 embedding 不是一个单词。</p>
<p>ensemble </p>
<ul>
<li>**n.**乐团；整体；全体；全套服装</li>
<li>合奏；重唱；系综</li>
</ul>
<p>embed </p>
<ul>
<li>**v.**把…牢牢地嵌入（或插入、埋入）；派遣（战地记者、摄影记者等）</li>
<li>使嵌入；内嵌；把…嵌入</li>
</ul>
<p>集成学习算法本身不算一种单独的机器学习算法，而是通过构建并结合多个机器学习器来完成学习任务。可以说是集百家之所长，能在机器学习算法中拥有较高的准确率，不足之处就是模型的训练过程可能比较复杂，效率不是很高。</p>
<h2 id="Q：什么是-OOF"><a href="#Q：什么是-OOF" class="headerlink" title="Q：什么是 OOF ?"></a>Q：什么是 OOF ?</h2><p>好像指的是交叉验证。</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/appleyuchi/article/details/100128835">https://blog.csdn.net/appleyuchi/article/details/100128835</a></p>
<h2 id="Q-什么是-Triplet-Loss？"><a href="#Q-什么是-Triplet-Loss？" class="headerlink" title="Q: 什么是 Triplet-Loss？"></a>Q: 什么是 Triplet-Loss？</h2><p><strong>参考：</strong><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/u013082989/article/details/83537370">https://blog.csdn.net/u013082989/article/details/83537370</a><br><a target="_blank" rel="noopener" href="https://omoindrot.github.io/triplet-loss#offline-and-online-triplet-mining">https://omoindrot.github.io/triplet-loss#offline-and-online-triplet-mining</a></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="category-chain-item">人工智能</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="print-no-link">#深度学习</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>深度学习Q&amp;A</div>
      <div>https://zyweven.github.io/2020/07/04/深度学习Q&amp;A/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>even zhang</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2020年7月4日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2020/07/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%97%AE%E7%AD%94%E7%AC%94%E8%AE%B0/" title="深度学习问答笔记">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">深度学习问答笔记</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2020/04/13/windows%E5%AE%89%E8%A3%85pymouse/" title="windows安装pymouse">
                        <span class="hidden-mobile">windows安装pymouse</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
